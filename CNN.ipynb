{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-01-22T16:26:34.751414Z",
     "start_time": "2021-01-22T16:26:33.125195Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import string\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.model_selection import cross_val_score\n",
    "# from sklearn.cluster import KMeans\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D, MaxPooling1D\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('attempt_1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Still to do: \n",
    "- Combine all text data (tweet and description) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:17:38.128607Z",
     "start_time": "2020-12-18T10:17:38.120960Z"
    }
   },
   "outputs": [],
   "source": [
    "def remove_punctuation(x):\n",
    "    return ''.join([i for i in x if i not in string.punctuation])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:28:19.308169Z",
     "start_time": "2020-12-18T10:28:19.296281Z"
    }
   },
   "outputs": [],
   "source": [
    "y_array = array([col for col in df['expert']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:19:32.903098Z",
     "start_time": "2020-12-18T10:19:32.556262Z"
    }
   },
   "outputs": [],
   "source": [
    "corpus = (df['full_text'].apply(remove_punctuation)).to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:21:44.324407Z",
     "start_time": "2020-12-18T10:21:43.553546Z"
    }
   },
   "outputs": [],
   "source": [
    "word_tokenizer = Tokenizer()\n",
    "word_tokenizer.fit_on_texts(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:22:06.235897Z",
     "start_time": "2020-12-18T10:22:06.223935Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56385"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_length = len(word_tokenizer.word_index) + 1\n",
    "vocab_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:23:28.830676Z",
     "start_time": "2020-12-18T10:23:28.222814Z"
    }
   },
   "outputs": [],
   "source": [
    "embedded_sentences = word_tokenizer.texts_to_sequences(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:24:16.695159Z",
     "start_time": "2020-12-18T10:24:16.691373Z"
    }
   },
   "outputs": [],
   "source": [
    "length_long_sentence = 280"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:24:22.777713Z",
     "start_time": "2020-12-18T10:24:22.606911Z"
    }
   },
   "outputs": [],
   "source": [
    "padded_sentences = pad_sequences(embedded_sentences, length_long_sentence, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:25:09.650184Z",
     "start_time": "2020-12-18T10:25:09.631045Z"
    }
   },
   "outputs": [],
   "source": [
    "embeddings_dictionary = dict()\n",
    "glove_file = open('/Users/ella.franks/Desktop/Projects/Datasets/glove.6B/glove.6B.100d.txt', encoding=\"utf8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:25:35.784920Z",
     "start_time": "2020-12-18T10:25:23.104872Z"
    }
   },
   "outputs": [],
   "source": [
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary [word] = vector_dimensions\n",
    "\n",
    "glove_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:25:46.273367Z",
     "start_time": "2020-12-18T10:25:46.150362Z"
    }
   },
   "outputs": [],
   "source": [
    "embedding_matrix = zeros((vocab_length, 100))\n",
    "for word, index in word_tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:26:19.220560Z",
     "start_time": "2020-12-18T10:26:18.976454Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "embedding_layer = Embedding(vocab_length, 100, weights=[embedding_matrix], input_length=length_long_sentence, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "# model.add(Flatten())\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(128, 5, activation='relu'))\n",
    "model.add(GlobalMaxPooling1D())\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:26:24.592674Z",
     "start_time": "2020-12-18T10:26:24.567305Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 280, 100)          5638500   \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 276, 128)          64128     \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 138, 128)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 134, 128)          82048     \n",
      "_________________________________________________________________\n",
      "global_max_pooling1d (Global (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 5,801,317\n",
      "Trainable params: 162,817\n",
      "Non-trainable params: 5,638,500\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:32:04.138447Z",
     "start_time": "2020-12-18T10:28:22.352274Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "491/491 [==============================] - 37s 76ms/step - loss: 0.3046 - acc: 0.8779 - val_loss: 0.2183 - val_acc: 0.8843\n",
      "Epoch 2/5\n",
      "491/491 [==============================] - 41s 83ms/step - loss: 0.2131 - acc: 0.9225 - val_loss: 0.3960 - val_acc: 0.8328\n",
      "Epoch 3/5\n",
      "491/491 [==============================] - 44s 90ms/step - loss: 0.1624 - acc: 0.9441 - val_loss: 0.3647 - val_acc: 0.8517\n",
      "Epoch 4/5\n",
      "491/491 [==============================] - 49s 99ms/step - loss: 0.1162 - acc: 0.9603 - val_loss: 0.5043 - val_acc: 0.8445\n",
      "Epoch 5/5\n",
      "491/491 [==============================] - 49s 100ms/step - loss: 0.0749 - acc: 0.9743 - val_loss: 0.3780 - val_acc: 0.8942\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8867464410>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(padded_sentences, y_array, epochs=5, verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:32:10.614112Z",
     "start_time": "2020-12-18T10:32:10.606358Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.8843017220497131,\n",
       " 0.832823634147644,\n",
       " 0.8516819477081299,\n",
       " 0.844546377658844,\n",
       " 0.8942405581474304]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.history.history['val_acc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-12-18T10:48:05.901645Z",
     "start_time": "2020-12-18T10:48:04.539457Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/ella.franks/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Model.state_updates (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "WARNING:tensorflow:From /Users/ella.franks/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/training/tracking/tracking.py:111: Layer.updates (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This property should not be used in TensorFlow 2.0, as updates are applied automatically.\n",
      "INFO:tensorflow:Assets written to: 1st_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"1st_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using saved model to predict on new tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get access to new data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweepy_expert",
   "language": "python",
   "name": "tweepy_expert"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
